import torch
import clip
import faiss
import numpy as np
from PIL import Image
import os

# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
device = "cuda" if torch.cuda.is_available() else "cpu"

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ CLIP
print("[üß†] –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å CLIP...")
model, preprocess = clip.load("ViT-B/32", device=device)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤
if not os.path.exists("clip.index"):
    raise FileNotFoundError("[‚ùå] –ù–µ –Ω–∞–π–¥–µ–Ω FAISS-–∏–Ω–¥–µ–∫—Å clip.index")

if not os.path.exists("clip_filenames.txt"):
    raise FileNotFoundError("[‚ùå] –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª clip_filenames.txt")

# –ó–∞–≥—Ä—É–∑–∫–∞ FAISS-–∏–Ω–¥–µ–∫—Å–∞ –∏ —Å–ø–∏—Å–∫–∞ –∏–º—ë–Ω
print("[üì¶] –ó–∞–≥—Ä—É–∂–∞–µ–º FAISS-–∏–Ω–¥–µ–∫—Å –∏ —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤...")
faiss_index = faiss.read_index("clip.index")

with open("clip_filenames.txt", "r", encoding="utf-8") as f:
    filenames = [line.strip() for line in f]

def match_clip(image: Image.Image):
    if image is None:
        raise ValueError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ")

    image_input = preprocess(image).unsqueeze(0).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image_input).cpu().numpy()
        image_features /= np.linalg.norm(image_features, axis=1, keepdims=True)

    _, index = faiss_index.search(image_features, k=1)

    matched_index = int(index[0][0])
    if matched_index >= len(filenames):
        raise IndexError(f"–ù–µ–≤–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å: {matched_index}, —Ñ–∞–π–ª–æ–≤ –≤ —Å–ø–∏—Å–∫–µ: {len(filenames)}")

    matched_filename = filenames[matched_index]

    print(f"[üéØ] –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {matched_filename} (index: {matched_index})")
    return matched_filename

# –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å FastAPI
match_image_to_video = match_clip
